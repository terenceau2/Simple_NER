{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Welcome!\n",
    "\n",
    "This notebook is a tutorial of how to do named entity recognition (NER) using HMM model. \n",
    "In a HMM model, we assume that the hidden state (named entity state) transition from one to another, then emit an observation (the token)\n",
    "Therefore we need to train the transition and emission probabilities. \n",
    "|\n",
    "The inference will find a path that maximizes the tag sequence's probability.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Util functions for data preparation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(filename,delimiter=','):\n",
    "    \n",
    "    with open(filename) as myfile:\n",
    "            data = myfile.readlines()\n",
    "            data = [i.rstrip('\\n') for i in data]\n",
    "\n",
    "    data = [i.split(delimiter) for i in data]\n",
    "\n",
    "\n",
    "\n",
    "    for i in data:\n",
    "                if i != [''] and i!=[]:\n",
    "                    del i[1]\n",
    "                    del i[1]  # delete the middle 2 columns from the data\n",
    "    for i in range(0, len(data)):\n",
    "                if data[i] == [''] or data[i]==[]:\n",
    "                    data[i] = [\"\", \"O\"]\n",
    "\n",
    "\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word2sents(data_string_list):\n",
    "    data = list()\n",
    "    X = list()\n",
    "    Y = list()\n",
    "    for data_string in data_string_list:\n",
    "\n",
    "        if data_string == ['', 'O'] or data_string == ['']:\n",
    "            if X == ['-DOCSTART-']:\n",
    "                X = list()\n",
    "                Y = list()\n",
    "                continue\n",
    "\n",
    "            data.append((X, Y))\n",
    "            X = list()\n",
    "            Y = list()\n",
    "        else:\n",
    "\n",
    "            X.append(data_string[0])\n",
    "            Y.append(data_string[-1])\n",
    "\n",
    "    if len(X) > 0:\n",
    "        data.append((X, Y))\n",
    "\n",
    "    data = [x for x in data if len(x) != 0]\n",
    "\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tags_space=['B-PER', 'B-LOC', 'B-ORG','B-MISC', 'I-PER', 'I-LOC', 'I-ORG', 'I-MISC', 'O']\n",
    "\n",
    "\"\"\"\n",
    "the data should be in CoNLL-2003 dataset's format.\n",
    "each line looks like this:\n",
    "(this tutorial does not provide the CoNLL-2003 annotated dataset)\n",
    "\n",
    "-DOCSTART- -X- O O\n",
    "\n",
    "EU NNP I-NP I-ORG\n",
    "rejects VBZ I-VP O\n",
    "German JJ I-NP I-MISC\n",
    "call NN I-NP O\n",
    "to TO I-VP O\n",
    "boycott VB I-VP O\n",
    "British JJ I-NP I-MISC\n",
    "lamb NN I-NP O\n",
    ". . O O\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "train_path='/Users/terenceau1/PycharmProjects/pythonProject/data/eng.train'\n",
    "\n",
    "conll_train = preprocess(train_path, delimiter=' ')\n",
    "\n",
    "train_set = word2sents(conll_train)\n",
    "#each element is a tuple of (tokens, tags)\n",
    "\n",
    "\n",
    "\n",
    "test_path='/Users/terenceau1/PycharmProjects/pythonProject/data/eng.testb'\n",
    "conll_test=preprocess(test_path,delimiter=' ')\n",
    "\n",
    "test_set=word2sents(conll_test)\n",
    "\n",
    "y_truth=[sent[1] for sent in test_set]  #the ground truth labels for the test set.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the vocabulary of the training set\n",
    "\n",
    "sentences=[x[0] for x in train_set]\n",
    "words=[]\n",
    "for sentence in sentences:\n",
    "# Iterate over each item in the sublist\n",
    "    for word in sentence:\n",
    "    # Append each item to the flattened list\n",
    "        words.append(word)\n",
    "\n",
    "\n",
    "\n",
    "words=[x for x in words if x!='']\n",
    "words=list(set(words))\n",
    "words=sorted(words, key=lambda L: (L.lower(), L))\n",
    "\n",
    "\n",
    "\n",
    "tag2idx= {w: i for i, w in enumerate(tags_space)}\n",
    "word2idx= {w: i for i, w in enumerate(words)}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Util functions for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def t2_given_t1(t2, t1, train_dataset):\n",
    "\n",
    "\n",
    "    count_t2_t1 = 0\n",
    "    for k in range(0 ,len(train_dataset)):\n",
    "\n",
    "        tags =train_dataset[k][1]\n",
    "\n",
    "        for index in range(len(tags ) -1):\n",
    "            if tags[index ]==t1 and tags[index +1] == t2:\n",
    "                count_t2_t1 += 1\n",
    "    return count_t2_t1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def word_given_tag(word, tag, train_dataset):\n",
    "    count_tag =0\n",
    "    count_w_given_tag =0\n",
    "    for k in range(0 ,len(train_dataset)):\n",
    "        sent =train_dataset[k]\n",
    "        for j in range(0 ,len(sent[0])):\n",
    "            if sent[1][j ]==tag:\n",
    "                count_tag+=1\n",
    "                if sent[0][j ]==word:\n",
    "                    count_w_given_tag+=1\n",
    "\n",
    "\n",
    "    return (count_w_given_tag, count_tag)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train the transition matrix\n",
    "\n",
    "\n",
    "transition_matrix = np.zeros((len(tags_space) , len(tags_space)), dtype='float32')\n",
    "for i, t1 in enumerate(list(tags_space)):\n",
    "        occurrence_t1=0\n",
    "        for j, t2 in enumerate(list(tags_space)):\n",
    "            occurrence_t1+= t2_given_t1(t2,t1,train_set)\n",
    "\n",
    "\n",
    "\n",
    "        for j, t2 in enumerate(list(tags_space)):\n",
    "\n",
    "            try:\n",
    "\n",
    "                transition_matrix[i, j] =  t2_given_t1(t2, t1, train_set) / occurrence_t1\n",
    "                                    #t2 given t1 means, t1 first, then t2\n",
    "\n",
    "\n",
    "            except:\n",
    "                transition_matrix[i, j]=0\n",
    "\n",
    "\n",
    "row_sums = transition_matrix.sum(axis=1)\n",
    "\n",
    "#this handles cases where some entries in row_sums=0\n",
    "for i in range(transition_matrix.shape[0]):\n",
    "    if row_sums[i] != 0:\n",
    "        transition_matrix[i] /= row_sums[i]\n",
    "    else:\n",
    "        # Handle rows with sum zero separately\n",
    "        #which means, the \"from\" state is never encountered.\n",
    "        transition_matrix[i] = np.zeros(transition_matrix.shape[1])\n",
    "\n",
    "\n",
    "#we can visualize it clearer in pandas dataframe\n",
    "transition_df=pd.DataFrame(transition_matrix, columns=tags_space, index=tags_space)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_dist=np.zeros((1,len(tags_space)),dtype='float32')\n",
    "\n",
    "for j in range(0,len(train_set)):\n",
    "    first_word_tag = train_set[j][1][0]\n",
    "\n",
    "    initial_dist[0,tag2idx[first_word_tag]]+= 1 #the initial distribution\n",
    "#this row is unnormalized for now. It will be normalized in the next step (to make them sum to 1)\n",
    "\n",
    "row_sums = initial_dist.sum(axis=1)\n",
    "initial_dist /= initial_dist.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train emission matrix\n",
    "\n",
    "\n",
    "emission_matrix = np.zeros((len(tags_space), len(word2idx)), dtype='float32')\n",
    "\n",
    "for i in range(0,len(train_set)):\n",
    "    sent=train_set[i]\n",
    "    for j in range(0,len(sent[0])):\n",
    "        word=sent[0][j]\n",
    "        tag=sent[1][j]\n",
    "        emission_matrix[tag2idx[tag],word2idx[word]]+=1\n",
    "\n",
    "\n",
    "\n",
    "row_sums = emission_matrix.sum(axis=1)\n",
    "\n",
    "\n",
    "#normalize\n",
    "\n",
    "for i in range(emission_matrix.shape[0]):\n",
    "    if row_sums[i] != 0:\n",
    "        emission_matrix[i] /= row_sums[i]\n",
    "    else:\n",
    "        # Handle rows with sum zero separately\n",
    "        emission_matrix[i] = np.zeros(emission_matrix.shape[1])\n",
    "\n",
    "\n",
    "emission_df = pd.DataFrame(emission_matrix, columns=list(word2idx.keys()), index=list(tags_space))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils for inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def viterbi_new(obs, trans_matrix, emit_matrix, initial_dist ,tag2idx ,word2idx):\n",
    "    # the obs is of length T, the trans matrix is of size C time C.\n",
    "\n",
    "    states =list(tag2idx.keys())\n",
    "\n",
    "    # Step 2: Initialize Variables\n",
    "    viterbi_table = [[0.0 for _ in range(len(states))] for _ in range(len(obs))]\n",
    "    backpointer = [[\"O\" for _ in range(len(states))] for _ in range(len(obs))]\n",
    "    # list of length T, each being a sublist of length \"C\"\n",
    "\n",
    "    backpointer[0 ] =[\"START\" for _ in range(len(states))]\n",
    "\n",
    "    if obs[0] in word2idx:\n",
    "\n",
    "        emit_probs =emit_matrix[: ,word2idx[obs[0]]]\n",
    "    else:\n",
    "        emit_probs =np.ones((len(states),) ,dtype='float32')\n",
    "\n",
    "    # viterbi_table[0]=initial_dist*emit_probs\n",
    "    # the for-loop version of the element-wise vector multiplication above (for loop is slower, but clearer for readability)\n",
    "    for s in range(0 ,len(states)):\n",
    "        viterbi_table[0][s] = initial_dist[0, s] * emit_probs[s]\n",
    "\n",
    "    probs = viterbi_table[0]\n",
    "\n",
    "\n",
    "    nonzero_probs = [x for x in probs if x != 0]\n",
    "    if nonzero_probs == []:\n",
    "        probs =[0.01 for _ in range(len(states))]  # in the degenerate case where, all current state has prob=0, ie.\n",
    "        # hmm encounters a situation where current observation is absolutely impossible\n",
    "        # we assumes a uniform potential so the inference can continue at future time steps\n",
    "    else:\n",
    "        _, scale_constant = adjust_numbers_to_range(nonzero_probs, target_min=1 ,target_max=100) #scale them so they dont get too big or too small (for stability)\n",
    "        probs =[ x *scale_constant for x in probs]\n",
    "\n",
    "\n",
    "    viterbi_table[0] =probs\n",
    "\n",
    "\n",
    "\n",
    "    # Step 3: Calculate Probabilities\n",
    "    for t in range(1 ,len(obs)):\n",
    "\n",
    "        if obs[t] in word2idx:\n",
    "\n",
    "            emit_probs = emit_matrix[:, word2idx[obs[t]]]\n",
    "        else:\n",
    "            emit_probs = np.ones(( len(states),), dtype='float32')\n",
    "\n",
    "\n",
    "\n",
    "        for s in states:  # s is current state\n",
    "            trans_probs =[viterbi_table[ t -1][tag2idx[prev_s]] * trans_matrix[tag2idx[prev_s] ,tag2idx[s]] for prev_s in states]\n",
    "\n",
    "\n",
    "\n",
    "            max_trans_probs = max(trans_probs)\n",
    "            # max_trans_probs is the max transition prob, from the most likely previous state\n",
    "            if max_trans_probs ==0.0:\n",
    "                best_prev_state ='O'\n",
    "            else:\n",
    "                best_prev_state =np.argmax(trans_probs)\n",
    "                best_prev_state =states[best_prev_state]\n",
    "\n",
    "\n",
    "            viterbi_table[t][tag2idx[s]] = max_trans_probs * emit_probs[tag2idx[s]]\n",
    "\n",
    "            backpointer[t][tag2idx[s]] = best_prev_state\n",
    "\n",
    "        probs = viterbi_table[t]\n",
    "\n",
    "        nonzero_probs = [x for x in probs if x != 0]\n",
    "        if nonzero_probs==[]:\n",
    "            probs = [0.01 for _ in\n",
    "                     range(len(states))]\n",
    "        else:\n",
    "            _, scale_constant = adjust_numbers_to_range(nonzero_probs, target_min=1, target_max=100)\n",
    "            probs = [x * scale_constant for x in probs]\n",
    "        viterbi_table[t] = probs\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # Step 4: Traceback and Find Best Path\n",
    "    best_path_prob = max(viterbi_table[-1])\n",
    "    # best_path_pointer = max(range(len(states)), key=lambda s: viterbi_table[-1][s])\n",
    "    best_end_state =states[np.argmax(viterbi_table[-1])]\n",
    "\n",
    "\n",
    "    best_path = [best_end_state]\n",
    "    for t in range(len(obs ) -1, 0, -1):\n",
    "        best_path.insert(0, backpointer[t][tag2idx[best_path[0]]])\n",
    "\n",
    "    # Step 5: Return Best Path\n",
    "    return best_path, best_path_prob ,viterbi_table,backpointer\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_numbers_to_range(numbers, target_max=1000, target_min=10, base=10):\n",
    "\n",
    "\n",
    "    largest_number=max(numbers)\n",
    "    scale_down_constant=1\n",
    "    if largest_number>target_max:\n",
    "\n",
    "\n",
    "        scale_down_power =0\n",
    "        while largest_number * (base ** -scale_down_power) > target_max:\n",
    "            scale_down_power += 1\n",
    "        #scale_down_power-= 1\n",
    "\n",
    "\n",
    "        scale_down_constant=base**(-scale_down_power)\n",
    "        numbers = [num * scale_down_constant for num in numbers]\n",
    "\n",
    "\n",
    "    # Find the smallest positive number in the list\n",
    "    smallest_number = min(numbers)\n",
    "    scale_up_constant=1\n",
    "\n",
    "    if smallest_number<target_min:\n",
    "\n",
    "        scale_up_power =0\n",
    "        while smallest_number * (base ** scale_up_power) < target_min:\n",
    "            scale_up_power += 1\n",
    "        #scale_up_power-= 1\n",
    "\n",
    "        # Calculate the constant (power of 10)\n",
    "        scale_up_constant = base ** scale_up_power\n",
    "\n",
    "        # Multiply all numbers by the constant\n",
    "        numbers = [num * scale_up_constant for num in numbers]\n",
    "\n",
    "\n",
    "\n",
    "    power=scale_up_constant*scale_down_constant\n",
    "\n",
    "    return numbers,power\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#just the tokens of the test dataset\n",
    "test_dataset_tokens=[sent[0] for sent in test_set]\n",
    "\n",
    "all_predictions=[]\n",
    "\n",
    "for i in range(0,len(test_dataset_tokens)):\n",
    "\n",
    "        sent=test_dataset_tokens[i]\n",
    "\n",
    "\n",
    "\n",
    "        ans, prob, V, b = viterbi_new(obs=test_dataset_tokens[i],trans_matrix=  transition_matrix, emit_matrix=emission_matrix,\n",
    "                                    initial_dist= initial_dist, tag2idx= tag2idx, word2idx=word2idx)\n",
    "\n",
    "\n",
    "        all_predictions.append(ans)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils for evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def endofphrase(prev, current):#if the previous word is the last word of a NE phrase, then returns true\n",
    "    answer=False\n",
    "    if prev.startswith(\"B\") and current.startswith(\"B\"):\n",
    "        answer=True\n",
    "    if prev.startswith(\"B\") and current.startswith(\"O\"):\n",
    "        answer=True\n",
    "    if prev.startswith(\"I\") and current.startswith(\"B\"):\n",
    "        answer=True\n",
    "    if prev.startswith(\"I\") and current.startswith(\"O\"):\n",
    "        answer=True\n",
    "    if prev!=\"O\" and current!=\"O\" and prev[2:]!=current[2:]:\n",
    "        answer=True\n",
    "    return answer\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def startofphrase(prev, current):  #if the current word is the first word of a NE phrase, then returns true\n",
    "    answer=False\n",
    "    if current.startswith(\"B\"):\n",
    "        answer=True\n",
    "    if prev.startswith(\"O\") and current.startswith(\"I\"):\n",
    "        answer=True\n",
    "    if prev!=\"O\" and current!=\"O\" and prev[2:]!=current[2:]:\n",
    "        answer=True\n",
    "    return answer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def performance_basic(predlist,truelist):\n",
    "    if len(predlist)!=len(truelist):\n",
    "        #sanity check\n",
    "        print(\"not same!!!\")\n",
    "        return None\n",
    "    total = len(predlist)\n",
    "    tp = 0\n",
    "    retrieved = 0\n",
    "    relevant = 0\n",
    "    correct=0\n",
    "\n",
    "    check=False #checks if the prediction matches the true tag. this turns true when both detects a start a phrase. It remains true until an error occurs, or if the phrase ends\n",
    "\n",
    "\n",
    "    if total>1:\n",
    "\n",
    "        #loop through the sentence. True positive, retrieved and relevant are all counted on a phrase-basis (one phrase is counted as 1)\n",
    "\n",
    "        for i in range(0,total):\n",
    "            if i==0:\n",
    "                trueprev='O'\n",
    "                predprev='O'\n",
    "            else:\n",
    "                trueprev = truelist[i - 1]\n",
    "                predprev = predlist[i - 1]\n",
    "\n",
    "\n",
    "            truecurrent=truelist[i]\n",
    "            predcurrent = predlist[i]\n",
    "\n",
    "\n",
    "            if startofphrase(trueprev,truecurrent)==True:\n",
    "                relevant+=1\n",
    "\n",
    "            if startofphrase(predprev,predcurrent)==True:\n",
    "                retrieved+=1\n",
    "\n",
    "            if check==True:\n",
    "                if endofphrase(trueprev,truecurrent) ==True and endofphrase(predprev,predcurrent)==True and trueprev[2:]==predprev[2:]:\n",
    "                    tp+=1\n",
    "                    check=False\n",
    "                if truecurrent[2:]!=predcurrent[2:] or endofphrase(trueprev,truecurrent)!=endofphrase(predprev,predcurrent):\n",
    "                    check=False\n",
    "\n",
    "            if startofphrase(trueprev, truecurrent) == True and startofphrase(predprev,predcurrent) == True and truecurrent[2:] == predcurrent[2:]:\n",
    "                        check = True\n",
    "                \n",
    "        if check==True: #this is to fill in the gap of the for-loop above. if the last word is in a NE and so far the check is ok , then this is also a true positive\n",
    "            tp+=1\n",
    "\n",
    "    elif total==1: #one-token sentence\n",
    "\n",
    "        if truelist[0] == predlist[0]:\n",
    "            correct += 1\n",
    "\n",
    "\n",
    "        if truelist[0] != \"O\":\n",
    "            relevant += 1\n",
    "\n",
    "        if predlist[0] != \"O\":\n",
    "            retrieved += 1\n",
    "        if truelist[0] == predlist[0] and truelist[0]!='O':\n",
    "            tp+=1\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    #you can print it if you want, to inspect it\n",
    "    print(\"Total:\",total)\n",
    "    print(\"Releant:\" , relevant)\n",
    "    print(\"Retrieved:\" , retrieved)\n",
    "    print(\"TP:\" , tp)\n",
    "    \"\"\"\n",
    "\n",
    "    return relevant,retrieved,tp\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaulation step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HMM &  70.9 & 55.5 & 62.2 & 3133 & 4418 & 5648 \n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "tp = 0\n",
    "retrieved = 0\n",
    "relevant= 0\n",
    "\n",
    "\n",
    "results=[]\n",
    "\n",
    "\n",
    "for i in range(0,len(all_predictions)):\n",
    "\n",
    "    truelist=y_truth[i]\n",
    "    predlist=all_predictions[i]\n",
    "    relevant,retrieved,tp=performance_basic(predlist,truelist)\n",
    "\n",
    "    result=(relevant,retrieved,tp)\n",
    "\n",
    "\n",
    "\n",
    "    results.append(result)\n",
    "\n",
    "\n",
    "\n",
    "relevant = [x[0] for x in results]\n",
    "relevant = sum(relevant)\n",
    "\n",
    "retrieved = [x[1] for x in results]\n",
    "retrieved = sum(retrieved)\n",
    "\n",
    "tp = [x[2] for x in results]\n",
    "tp = sum(tp)\n",
    "\n",
    "\n",
    "\n",
    "try:\n",
    "    precision = tp / retrieved\n",
    "except:\n",
    "    precision=0\n",
    "\n",
    "\n",
    "try:\n",
    "    recall = tp / relevant\n",
    "except:\n",
    "    recall=0\n",
    "\n",
    "try:\n",
    "    fscore = 2 * precision * recall / (precision + recall)\n",
    "except:\n",
    "    fscore=0\n",
    "\n",
    "\n",
    "precision=round(precision*100,1)\n",
    "recall=round(recall*100,1)\n",
    "fscore=round(fscore*100,1)\n",
    "\n",
    "\n",
    "\n",
    "#print(relevant)\n",
    "print(f\"HMM &  {precision} & {recall} & {fscore} & {tp} & {retrieved} & {relevant} \")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusions\n",
    "\n",
    "We have shown how to do NER using HMM. If trained and tested CoNLL-2003 dataset,\n",
    "it should have 70.9% precision, 55.5% recall and 62.2% F-score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
